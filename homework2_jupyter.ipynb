{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import datafiles\n",
    "with open('PA_businesses.json', \"r\") as read_file:\n",
    "    ratings = json.load(read_file) \n",
    "    \n",
    "with open('PA_reviews_full.json', \"r\") as read_file:\n",
    "    reviews = json.load(read_file)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1RHY4K3BD22FK7Cfftn8Mg</td>\n",
       "      <td>Marathon Diner</td>\n",
       "      <td>Center Core - Food Court, Fl 3, Pittsburgh Int...</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15231</td>\n",
       "      <td>40.496177</td>\n",
       "      <td>-80.246011</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsTakeOut': 'True', 'BusinessParkin...</td>\n",
       "      <td>Sandwiches, Salad, Restaurants, Burgers, Comfo...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>dQj5DLZjeDK3KFysh1SYOQ</td>\n",
       "      <td>Apteka</td>\n",
       "      <td>4606 Penn Ave</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15224</td>\n",
       "      <td>40.465694</td>\n",
       "      <td>-79.949324</td>\n",
       "      <td>4.5</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>{'CoatCheck': 'False', 'BusinessParking': '{'g...</td>\n",
       "      <td>Nightlife, Bars, Polish, Modern European, Rest...</td>\n",
       "      <td>{'Wednesday': '17:0-0:0', 'Thursday': '17:0-0:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>v-scZMU6jhnmV955RSzGJw</td>\n",
       "      <td>No. 1 Sushi Sushi</td>\n",
       "      <td>436 Market St</td>\n",
       "      <td>Pittsburgh</td>\n",
       "      <td>PA</td>\n",
       "      <td>15222</td>\n",
       "      <td>40.441062</td>\n",
       "      <td>-80.002126</td>\n",
       "      <td>4.5</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>{'OutdoorSeating': 'False', 'HasTV': 'True', '...</td>\n",
       "      <td>Japanese, Sushi Bars, Restaurants</td>\n",
       "      <td>{'Monday': '11:0-20:0', 'Tuesday': '11:0-20:0'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>KFbUQ-RR2UOV62Ep7WnXHw</td>\n",
       "      <td>Westwood Bar &amp; Grill</td>\n",
       "      <td>825 Commonwealth Ave</td>\n",
       "      <td>West Mifflin</td>\n",
       "      <td>PA</td>\n",
       "      <td>15122</td>\n",
       "      <td>40.376674</td>\n",
       "      <td>-79.882480</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>{'GoodForMeal': '{'dessert': False, 'latenight...</td>\n",
       "      <td>American (Traditional), Restaurants</td>\n",
       "      <td>{'Wednesday': '11:0-0:0', 'Thursday': '11:0-0:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>QHr_fc_TLnGfUEuDEa2jDg</td>\n",
       "      <td>PA Wine &amp; Spirits Store</td>\n",
       "      <td>125 Towne Centre Dr, Ste 500</td>\n",
       "      <td>Wexford</td>\n",
       "      <td>PA</td>\n",
       "      <td>15090</td>\n",
       "      <td>40.632053</td>\n",
       "      <td>-80.056476</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BikeParking': 'False', 'RestaurantsTakeOut':...</td>\n",
       "      <td>Beer, Wine &amp; Spirits, Food</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                     name  \\\n",
       "0  1RHY4K3BD22FK7Cfftn8Mg           Marathon Diner   \n",
       "1  dQj5DLZjeDK3KFysh1SYOQ                   Apteka   \n",
       "2  v-scZMU6jhnmV955RSzGJw        No. 1 Sushi Sushi   \n",
       "3  KFbUQ-RR2UOV62Ep7WnXHw     Westwood Bar & Grill   \n",
       "4  QHr_fc_TLnGfUEuDEa2jDg  PA Wine & Spirits Store   \n",
       "\n",
       "                                             address          city state  \\\n",
       "0  Center Core - Food Court, Fl 3, Pittsburgh Int...    Pittsburgh    PA   \n",
       "1                                      4606 Penn Ave    Pittsburgh    PA   \n",
       "2                                      436 Market St    Pittsburgh    PA   \n",
       "3                               825 Commonwealth Ave  West Mifflin    PA   \n",
       "4                       125 Towne Centre Dr, Ste 500       Wexford    PA   \n",
       "\n",
       "  postal_code   latitude  longitude  stars  review_count  is_open  \\\n",
       "0       15231  40.496177 -80.246011    4.0            35        1   \n",
       "1       15224  40.465694 -79.949324    4.5           242        1   \n",
       "2       15222  40.441062 -80.002126    4.5           106        1   \n",
       "3       15122  40.376674 -79.882480    3.0             5        1   \n",
       "4       15090  40.632053 -80.056476    3.0             7        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'RestaurantsTakeOut': 'True', 'BusinessParkin...   \n",
       "1  {'CoatCheck': 'False', 'BusinessParking': '{'g...   \n",
       "2  {'OutdoorSeating': 'False', 'HasTV': 'True', '...   \n",
       "3  {'GoodForMeal': '{'dessert': False, 'latenight...   \n",
       "4  {'BikeParking': 'False', 'RestaurantsTakeOut':...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Sandwiches, Salad, Restaurants, Burgers, Comfo...   \n",
       "1  Nightlife, Bars, Polish, Modern European, Rest...   \n",
       "2                  Japanese, Sushi Bars, Restaurants   \n",
       "3                American (Traditional), Restaurants   \n",
       "4                         Beer, Wine & Spirits, Food   \n",
       "\n",
       "                                               hours  \n",
       "0                                               None  \n",
       "1  {'Wednesday': '17:0-0:0', 'Thursday': '17:0-0:...  \n",
       "2  {'Monday': '11:0-20:0', 'Tuesday': '11:0-20:0'...  \n",
       "3  {'Wednesday': '11:0-0:0', 'Thursday': '11:0-0:...  \n",
       "4                                               None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving as dataframe \n",
    "df = pd.DataFrame(ratings['businesses']) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1, Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q1_yelp(data1,data2):\n",
    "    \n",
    "    #part one\n",
    "    df = pd.DataFrame(data1['businesses']) #saving as dataframe \n",
    "    df.head() #looking at dataframe for understanding\n",
    "    stars = df['stars'] #extracting stars and saving as pandas series \n",
    "    star_percentages = stars.value_counts()/len(stars)*100 #value counts gives you values gives you counts for each star \n",
    "\n",
    "    answer1 = pd.DataFrame(star_percentages).sort_index() #sorting the answers by index\n",
    "    \n",
    "    #part two\n",
    "    reviews_df = pd.DataFrame(data2['reviews']) #extract the dataframe and save it to a more digestible form \n",
    "    reviews_df['text'] = reviews_df['text'].str.split(' ') #split reviews by white space to get array of words \n",
    "    reviews_df['word_count'] = reviews_df['text'].apply(lambda x: len(x)) #create new column for wordcount\n",
    "    #for each row, count how many words (take length)\n",
    "    answer2 = pd.DataFrame(reviews_df.groupby(['stars']).mean()['word_count'])\n",
    "    \n",
    "    # return answer1a, answer1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'answer1a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-2b86a024b28a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0manswer1a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer1b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq1_yelp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreviews\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-9608f6565306>\u001b[0m in \u001b[0;36mq1_yelp\u001b[0;34m(data1, data2)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0manswer2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreviews_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0manswer1a\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswer1b\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'answer1a' is not defined"
     ]
    }
   ],
   "source": [
    "answer1a, answer1b = q1_yelp(ratings,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_yelp(ratings,reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1, Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q2_yelp(data1):\n",
    "    \n",
    "    #Part 1\n",
    "    df = pd.DataFrame(data1['businesses'])\n",
    "    df['categories'] = df['categories'].str.split(',').apply(lambda x: [i.strip().lower() for i in x]) \n",
    "    #Split categories by commas to get list of labels, remove white space at the start and end for all values, \n",
    "    #standardise so all the strings are in the same case\n",
    "\n",
    "    s = df.apply(lambda x: pd.Series(x['categories']),axis=1).stack().reset_index(level=1, drop=True)\n",
    "    s.name = 'label'\n",
    "    #create a variable to count unique category lables\n",
    "    #apply pd.Series to each row to turn list of categories into a big data frame,\n",
    "    #with columns corresponding to each category\n",
    "    #Stack into one big column of all labels and use set to identify unique \n",
    "\n",
    "    df_unstacked = df.drop('categories', axis=1).join(s)\n",
    "    #remove category label from column and combine with s\n",
    "  \n",
    "    answer1 = len(set(df_unstacked['label']))\n",
    "    \n",
    "    #Part 2 & 3\n",
    "    \n",
    "    label_df = pd.DataFrame(list(zip(df_unstacked.groupby('label').mean()['stars'],df_unstacked.groupby('label').count()['business_id'])),columns = ['mean_stars','counts'])\n",
    "    \n",
    "    #create a dataframe that contains by use of zip two columns: label and mean stars with column names etc \n",
    "    \n",
    "\n",
    "    label_df.index = df_unstacked.groupby('label').mean()['stars'].index\n",
    "    #for some reason index dispappeated\n",
    "    #relabel index using label names \n",
    "    \n",
    "    answer2 = label_df\n",
    "    \n",
    "    # return answer1,answer2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer2a, answer2bc = q2_yelp(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1, Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def q3_yelp(data): \n",
    "    df = pd.DataFrame(data['businesses'])\n",
    "\n",
    "    high_ratings = df[['attributes','stars']]\n",
    "    #create dataframe with attributes and stars \n",
    "    \n",
    "    dataframe = pd.DataFrame() #create empty dataframe\n",
    "    \n",
    "    for i in range(len(ratings['businesses'])): \n",
    "        dataframe = dataframe.append(pd.DataFrame(ratings['businesses'][i]['attributes'],index=[i]))\n",
    "        \n",
    "        #for each rating in the data set, extract attributes and turn them into a nicely formatted column\n",
    "        \n",
    "    dataframe['stars'] = df[['stars']]\n",
    "    \n",
    "    #bring stars data into our nicely formatted dataframe \n",
    "    \n",
    "    dataframe = dataframe[dataframe['stars']>3.5] #take values that are 4 or higher \n",
    "    \n",
    "    descriptive = dataframe.drop(['stars'],axis=1).describe() #get rid of the stars \n",
    "    #because we want summary statistics only of the attributes \n",
    "    \n",
    "    descriptive_keys = (descriptive.loc['count'][descriptive.loc['count']>500]).keys()\n",
    "    #take names of attributes of which we have more than 500 ratings because some ratings only exists once or twice\n",
    "    \n",
    "    ratings_filtered = dataframe[descriptive_keys]\n",
    "    \n",
    "    for i in ratings_filtered.columns:\n",
    "        print(i.upper())\n",
    "        print(ratings_filtered[i].value_counts() )\n",
    "        print()\n",
    "        \n",
    "    #print descriptive statistics for each attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wiki_api.py\n",
    "import hashlib, os, json, requests\n",
    "from lxml import etree\n",
    "\n",
    "# Input: Page name of a Wikipedia article.\n",
    "# Returns: Full HTML source of the named article if it exists,\n",
    "#          or None if no such page exists.\n",
    "def __api_GET_latest_page(title):\n",
    "    parameters = {\n",
    "        \"action\": \"parse\",\n",
    "        \"page\": title,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    response_json = __get(\"revisions\", title, parameters)\n",
    "    if(\"parse\" in response_json.keys() \n",
    "        and \"text\" in response_json[\"parse\"].keys() \n",
    "        and \"*\" in response_json[\"parse\"][\"text\"].keys()):\n",
    "        return response_json[\"parse\"][\"text\"][\"*\"]\n",
    "    return None    \n",
    "\n",
    "# Internal function to hide a caching API request into a single private function.\n",
    "# This function will save you a lot of headaches in writing your own HTTP requests\n",
    "# and will save the Wikimedia foundation some bandwidth since you'll fetch a local\n",
    "# copy if you have already retrieved an article text at least once.\n",
    "def __get(function_key, key, parameters, check_cache=True, write_cache=True):\n",
    "    target = \"https://en.wikipedia.org/w/api.php\"\n",
    "    cache_path = \"cached_api\"\n",
    "    params_unicode = str(parameters).encode('utf-8')\n",
    "    md5 = hashlib.md5(params_unicode).hexdigest()\n",
    "    return_json = None\n",
    "\n",
    "    cache_file = os.path.join(cache_path, function_key, str(key), md5)\n",
    "    cache_exists = os.path.isfile(cache_file)\n",
    "    if cache_exists:\n",
    "        try:\n",
    "            json_in = open(cache_file, \"r\")\n",
    "            json_str = json_in.read()\n",
    "            return_json = json.loads(json_str)\n",
    "            if \"error\" in return_json.keys() and \"code\" in return_json[\"error\"].keys() and return_json[\"error\"][\"code\"]==\"maxlag\":\n",
    "                cache_exists = False\n",
    "        except:\n",
    "            cache_exists = False\n",
    "\n",
    "    if not cache_exists:\n",
    "        cache_dir = os.path.dirname(cache_file)\n",
    "        if not os.path.isdir(cache_dir):\n",
    "            os.makedirs(cache_dir)\n",
    "        r = requests.get(target, params=parameters)\n",
    "        request_json = r.json()\n",
    "        json_out = open(cache_file, \"w\")\n",
    "        print(json.dumps(request_json), file=json_out)\n",
    "        return_json = request_json\n",
    "    return return_json\n",
    "\n",
    "# This function takes as input a parsed HTML tree and returns the same\n",
    "# tree but with a set of tags removed, mostly the contents of tables and scripts.\n",
    "# This makes parsing the actual contents of a page easier.\n",
    "def __remove_tables_and_scripts(tree):\n",
    "    tags_to_remove = [\"tbody\", \"td\", \"script\"]\n",
    "    for tag in tags_to_remove:\n",
    "        elements = tree.find(f\".//{tag}\")\n",
    "        if elements is not None:\n",
    "            for e in elements:\n",
    "                e.getparent().remove(e)\n",
    "    return tree\n",
    "\n",
    "# This function takes two required and one optional parameters as input.\n",
    "#\n",
    "# Required:\n",
    "# name: Name of a Wikipedia page to retrieve.\n",
    "# format: Type of content that you want returned. Options include:\n",
    "#         \"html\" : Full HTML content of the page you requested.\n",
    "#         \"text\" : Full content of the page you requested as a single string,\n",
    "#                  with all HTML tags removed.\n",
    "#         \"list\" : Full content of the page you requested with all HTML removed,\n",
    "#                  but each paragraph on the page is a separate string, and the\n",
    "#                  page as a whole is returned to you as a list of paragraphs.\n",
    "#\n",
    "# Optional:\n",
    "# include_tables: By default, all tables and scripts in the HTML text will be \n",
    "#                 removed from the text that gets sent back to you. If you want\n",
    "#                 to include that content, you can pass in True instead.\n",
    "#\n",
    "# This function returns the content of the page in the format that you specified.\n",
    "def page_text(name, format, include_tables = False):\n",
    "    try:\n",
    "        result = __api_GET_latest_page(name)\n",
    "    except:\n",
    "        print(\"API request failed.\")\n",
    "    if result:\n",
    "        e = etree.fromstring(result)\n",
    "        if not include_tables:\n",
    "            e = __remove_tables_and_scripts(e)\n",
    "        if format == \"html\":\n",
    "            return str(etree.tostring(e))\n",
    "        elif format == \"text\":\n",
    "            return ''.join(e.itertext())\n",
    "        elif format == \"list\":\n",
    "            return ''.join(e.itertext()).split('\\n')\n",
    "    else:\n",
    "        print(\"Failed to retrieve a page.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wiki_api import page_text\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
